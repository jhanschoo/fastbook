{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *\n",
    "setup_book()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Deep Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A First Look at the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *\n",
    "path = untar_data(URLs.ML_100k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file containing user ratings for movies\n",
    "# into a table with 4 columns: user, movie, rating, timestamp\n",
    "ratings = pd.read_csv(path/'u.data', delimiter='\\t', header=None,\n",
    "                      names=['user','movie','rating','timestamp'])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration of movie latent factors\n",
    "last_skywalker = np.array([0.98,0.9,-0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration of user latent factors\n",
    "user1 = np.array([0.9,0.8,-0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration of predicting rating from user and movie latent factors\n",
    "(user1*last_skywalker).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continued demonstration\n",
    "casablanca = np.array([-0.99,-0.3,0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continued demonstration\n",
    "(user1*casablanca).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the Latent Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file containing movie genre information and other metadata; we shall not use genre information\n",
    "# we use thes file only to get the movie titles\n",
    "# movies is a table with 2 columns: movie, title\n",
    "movies = pd.read_csv(path/'u.item',  delimiter='|', encoding='latin-1',\n",
    "                     usecols=(0,1), names=('movie','title'), header=None)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ratings and movies tables joining on movie column\n",
    "ratings = ratings.merge(movies)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataLoaders object from the ratings table, using titles to identify movies rather than movie ids\n",
    "# by default, 0th column is user_name, which correctly corresponds to our user column\n",
    "# by default, 1st column is item_name, which corresponds to our movie colume; we override this to use title\n",
    "# by default, 2nd column is rating_name, which correctly corresponds to our rating column\n",
    "# bs=64 is actually the default batch size, but we specify it here for clarity\n",
    "dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# echoes the two classes user and title, and their respective values\n",
    "dls.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users  = len(dls.classes['user'])\n",
    "n_movies = len(dls.classes['title'])\n",
    "n_factors = 5\n",
    "\n",
    "# create a matrix of 5 latint factors to represent each user\n",
    "user_factors = torch.randn(n_users, n_factors)\n",
    "# create a matrix of 5 latent factors to represent each movie\n",
    "movie_factors = torch.randn(n_movies, n_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration of extracting the 5 latent factors for a particular user (the 3rd 0-idx user) using matrix multiplication by a one-hot vector\n",
    "one_hot_3 = one_hot(3, n_users).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continued demonstration\n",
    "user_factors.t() @ one_hot_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration using index notation\n",
    "user_factors[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a PyTorch Module\n",
    "# but we first demonstrate a simple class\n",
    "class Example:\n",
    "    def __init__(self, a): self.a = a\n",
    "    def say(self,x): return f'Hello {self.a}, {x}.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration of instantiating an object of class Example and using it\n",
    "ex = Example('Sylvain')\n",
    "ex.say('nice to meet you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let us review the model's input and output\n",
    "# In its most general form, its input is the concatenation of two vectors:\n",
    "#   one vector contains unnormalized weights of users to consider\n",
    "#   the other vector contains unnormalized weights of movies to consider\n",
    "#   the output is how much our considered users like our considered movies weighted by the weights as a scalar\n",
    "# In the case of training on the rating a user gave a movie, the input is a one-hot vector of the user and a one-hot vector of the movie\n",
    "\n",
    "# Our module represents the learned laetnt factors of users and movies as two embedding layers; Embedding is meant for sparse data\n",
    "class DotProduct(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # recall that x[:,0] is the user column and x[:,1] is the movie column\n",
    "        # users is a matrix where the ith row contains the latent factors of the user in the ith row of x\n",
    "        #   so observe that this is the matrix multiplication of a list of one-hot vectors with the user_factors matrix\n",
    "        # movies is a matrix where the ith row contains the latent factors of the movie in the ith row of x\n",
    "        #   so observe that this is the matrix multiplication of a list of one-hot vectors with the movie_factors matrix\n",
    "        # if we had not been using the Embedding class, we would need to replace the user and movie columns with concatenated one-hot vectors\n",
    "        # thus note that users and movies have exactly the same shape\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        return (users * movies).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the first batch of data from the DataLoaders object\n",
    "x,y = dls.one_batch()\n",
    "# x is an array of shape (64,2), where each row is a pair of user and movie indices; note that our dataloader has re-indexed the users and movies\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate our model\n",
    "model = DotProduct(n_users, n_movies, 50)\n",
    "# instantiate a learner on our model and data\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train our model for 5 epochs, using a maximum learning rate of 5e-3\n",
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we revise the model to pass the output through a sigmoid function bounded between 0 and 5.5 (by default)\n",
    "class DotProduct(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        return sigmoid_range((users * movies).sum(dim=1), *self.y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we try training this model. Observe that lor loss is lower than the previous, until it starts to overfit\n",
    "model = DotProduct(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now capture in our model the intuition that some users are more critical than others, and some movies are better than others as bias vectors\n",
    "# I wonder if without these bias vectors (and regularization), the model would learn quality of movie as a latent factor (and e.g. one latent factor represents how much a user likes highly-rated movies)\n",
    "class DotProductBias(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.user_bias = Embedding(n_users, 1)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        self.movie_bias = Embedding(n_movies, 1)\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        res = (users * movies).sum(dim=1, keepdim=True)\n",
    "        res += self.user_bias(x[:,0]) + self.movie_bias(x[:,1])\n",
    "        return sigmoid_range(res, *self.y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model quickly overfits\n",
    "model = DotProductBias(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we illustrate L2 regularization\n",
    "# we add to the loss the sum of the squares of the latent factors, and see that larger latent factors have their errors penalized more\n",
    "x = np.linspace(-2,2,100)\n",
    "a_s = [1,2,5,10,50] \n",
    "ys = [a * x**2 for a in a_s]\n",
    "_,ax = plt.subplots(figsize=(8,6))\n",
    "for a,y in zip(a_s,ys): ax.plot(x,y, label=f'a={a}')\n",
    "ax.set_ylim([0,5])\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we specify wd=0.1 to use L2 regularization\n",
    "# note that the regularization contribution to the loss is not actually computed, but is instead added to the gradient\n",
    "model = DotProductBias(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Our Own Embedding Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now investigate what it takes to create a Module that replicates the Embedding layer\n",
    "\n",
    "# the parameters of the Module need to be registered with the Module\n",
    "#   but we see that we need to do more than naively initialize a tensor into a class member\n",
    "class T(Module):\n",
    "    def __init__(self): self.a = torch.ones(3)\n",
    "\n",
    "L(T().parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we observe that we may register a tensor as a parameter of the Module by wrapping it in nn.Parameter\n",
    "class T(Module):\n",
    "    def __init__(self): self.a = nn.Parameter(torch.ones(3))\n",
    "\n",
    "L(T().parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe that predefined PyTorch Modules such as nn.Linear register parameters with the enclosing class where appropriate, when instantiated\n",
    "# also note that t.a.parameters() returns an iterator over the same tensors as t.parameters() here, since t.a is the only member of t\n",
    "class T(Module):\n",
    "    def __init__(self): self.a = nn.Linear(1, 3, bias=False)\n",
    "\n",
    "t = T()\n",
    "L(t.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Linear Module, as with other torch modules, defines the weight class member just as we did above in\n",
    "#     class T(Module):\n",
    "#         def __init__(self): self.a = nn.Parameter(torch.ones(3))\n",
    "type(t.a.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use a helper function for initializing the weights of our DotProductBias model to small random values, and registering them as parameters directly, without using nn.Embedding\n",
    "def create_params(size):\n",
    "    return nn.Parameter(torch.zeros(*size).normal_(0, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the definition is largely identical to our previous definition of DotProductBias\n",
    "#   of note, the different way to specify the shape during instantiation,\n",
    "#   and the use of indexing [] to extract the latent factors where in using nn.Embedding we used () (specifying the indicer as an argument)\n",
    "class DotProductBias(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = create_params([n_users, n_factors])\n",
    "        self.user_bias = create_params([n_users])\n",
    "        self.movie_factors = create_params([n_movies, n_factors])\n",
    "        self.movie_bias = create_params([n_movies])\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors[x[:,0]]\n",
    "        movies = self.movie_factors[x[:,1]]\n",
    "        res = (users*movies).sum(dim=1)\n",
    "        res += self.user_bias[x[:,0]] + self.movie_bias[x[:,1]]\n",
    "        return sigmoid_range(res, *self.y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DotProductBias(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Embeddings and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with regularization, the biases represent the criticality of users and the quality of movies\n",
    "#   we sample the 5 most acclaimed movies, that are more universally enjoyed\n",
    "movie_bias = learn.model.movie_bias.squeeze()\n",
    "idxs = movie_bias.argsort()[:5]\n",
    "[dls.classes['title'][i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = movie_bias.argsort(descending=True)[:5]\n",
    "[dls.classes['title'][i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now plot movie similarity by the two most expressive latent factors, and similar movies are close together\n",
    "g = ratings.groupby('title')['rating'].count()\n",
    "top_movies = g.sort_values(ascending=False).index.values[:1000]\n",
    "top_idxs = tensor([learn.dls.classes['title'].o2i[m] for m in top_movies])\n",
    "movie_w = learn.model.movie_factors[top_idxs].cpu().detach()\n",
    "movie_pca = movie_w.pca(3)\n",
    "fac0,fac1,fac2 = movie_pca.t()\n",
    "idxs = list(range(50))\n",
    "X = fac0[idxs]\n",
    "Y = fac2[idxs]\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(X, Y)\n",
    "for i, x, y in zip(top_movies[idxs], X, Y):\n",
    "    plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using fastai.collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collab_learner is a helper function that creates a model (with bias for either dimension) and learner for collaborative filtering\n",
    "learn = collab_learner(dls, n_factors=50, y_range=(0, 5.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can access the model from the learner using learn.model (u for user, i for item)\n",
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_bias = learn.model.i_bias.weight.squeeze()\n",
    "idxs = movie_bias.argsort(descending=True)[:5]\n",
    "[dls.classes['title'][i] for i in idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to compute how similar two movies are by comparing their latent factors\n",
    "# we use the cosine similarity, which is the cosine of the angle between the two vectors\n",
    "# compare against taking the distance between the two vectors\n",
    "# we first extract the movie latent factors from the model as movie_factors\n",
    "# then obtain the index assigned to Silence of the Lambs, The (1991) by the dataloader\n",
    "# then compute the cosine similarity; (dim=1) is in fact the default, and it means that the dimensions are the latent factors, broadcasting over each movie (as opposed to each movie, broadcasting over each latent factor; in the second argument, [idx] extracts the latent factors for Silence of the Lambs, The (1991) as a len 50 vector, anc [None] reshapes it to a 1x50 matrix, so that it can be broadcast over the other movies)\n",
    "# then we sort the movies by cosine similarity, and extract the index of the most similar movie\n",
    "# finally, we look up the title of the most similar movie\n",
    "\n",
    "movie_factors = learn.model.i_weight.weight\n",
    "idx = dls.classes['title'].o2i['Silence of the Lambs, The (1991)']\n",
    "distances = nn.CosineSimilarity(dim=1)(movie_factors, movie_factors[idx][None])\n",
    "idx = distances.argsort(descending=True)[1]\n",
    "dls.classes['title'][idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping a Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert our classic collaborative filtering model to a deep learning model, we replace the dot product with a neural network\n",
    "# the inputs are the latent factors of the user and movie, concatenated\n",
    "# note that with this we can be more flexible with the number of latent factors; the users and movies can have different numbers of latent factors\n",
    "# here, we estimate a good number of latent factors for our set of users and movies\n",
    "# this cell may print [(944, 74), (1635, 101)], which means that there are 944 users and 1635 movies, and we estimate that 74 latent factors for users and 101 latent factors for movies is a good number\n",
    "embs = get_emb_sz(dls)\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_sz is a shape tuple for a matrix of the number of users by the number of latent factors for users\n",
    "# and similarly for item_sz\n",
    "# the nn is\n",
    "#   a linear layer with input size equal to the sum of the latent factors for users and movies mapping to n_act (100 by default) latent factors\n",
    "#   a ReLU activation function\n",
    "#   a linear layer with input size equal to n_act mapping to 1 output\n",
    "# the output is passed through a sigmoid function bounded between 0 and 5.5 (by default)\n",
    "class CollabNN(Module):\n",
    "    def __init__(self, user_sz, item_sz, y_range=(0,5.5), n_act=100):\n",
    "        self.user_factors = Embedding(*user_sz)\n",
    "        self.item_factors = Embedding(*item_sz)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(user_sz[1]+item_sz[1], n_act),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_act, 1))\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embs = self.user_factors(x[:,0]),self.item_factors(x[:,1])\n",
    "        x = self.layers(torch.cat(embs, dim=1))\n",
    "        return sigmoid_range(x, *self.y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe how our model instantiation params are meant to accept the output of get_emb_sz\n",
    "model = CollabNN(*embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_nn=True in fast.ai's collab_learner uses this model instead of the classic collaborative filtering model\n",
    "# layers specifies the number of layers and their sizes\n",
    "learn = collab_learner(dls, use_nn=True, y_range=(0, 5.5), layers=[100,50])\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the EmbeddingNN class is used by fast.ai's collab_learner when use_nn=True\n",
    "# observe that 176 = 74 + 102, which is the sum of the latent factors for users and movies\n",
    "# also observe that this is a specialization of TabularModel with n_cont=0 (no continuous variables) and out_sz=1 (one output),\n",
    "# since we may view collaborative filtering as a tabular problem with two categorical variables (user and movie) and one continuous variable (rating), where we have first converted the sparse categorical variables to embeddings (c.f. word embeddings). Note that TabularModel expects to first embed the categorical variables, so the shape to the categorical variables includes the not only the number of categories, but also the number of latent factors; the size of the embedding is estimated under the hood when we use collab_learner\n",
    "# EmbeddingNN(\n",
    "#   (embeds): ModuleList(\n",
    "#     (0): Embedding(944, 74)\n",
    "#     (1): Embedding(1665, 102)\n",
    "#   )\n",
    "#   (emb_drop): Dropout(p=0.0, inplace=False)\n",
    "#   (bn_cont): BatchNorm1d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#   (layers): Sequential(\n",
    "#     (0): LinBnDrop(\n",
    "#       (0): Linear(in_features=176, out_features=100, bias=False)\n",
    "#       (1): ReLU(inplace=True)\n",
    "#       (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     )\n",
    "#     (1): LinBnDrop(\n",
    "#       (0): Linear(in_features=100, out_features=50, bias=False)\n",
    "#       (1): ReLU(inplace=True)\n",
    "#       (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     )\n",
    "#     (2): LinBnDrop(\n",
    "#       (0): Linear(in_features=50, out_features=1, bias=True)\n",
    "#     )\n",
    "#     (3): fastai.layers.SigmoidRange(low=0, high=5.5)\n",
    "#   )\n",
    "# )\n",
    "@delegates(TabularModel)\n",
    "class EmbeddingNN(TabularModel):\n",
    "    def __init__(self, emb_szs, layers, **kwargs):\n",
    "        super().__init__(emb_szs, layers=layers, n_cont=0, out_sz=1, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sidebar: kwargs and Delegates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End sidebar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What problem does collaborative filtering solve?\n",
    "1. How does it solve it?\n",
    "1. Why might a collaborative filtering predictive model fail to be a very useful recommendation system?\n",
    "1. What does a crosstab representation of collaborative filtering data look like?\n",
    "1. Write the code to create a crosstab representation of the MovieLens data (you might need to do some web searching!).\n",
    "1. What is a latent factor? Why is it \"latent\"?\n",
    "1. What is a dot product? Calculate a dot product manually using pure Python with lists.\n",
    "1. What does `pandas.DataFrame.merge` do?\n",
    "1. What is an embedding matrix?\n",
    "1. What is the relationship between an embedding and a matrix of one-hot-encoded vectors?\n",
    "1. Why do we need `Embedding` if we could use one-hot-encoded vectors for the same thing?\n",
    "1. What does an embedding contain before we start training (assuming we're not using a pretained model)?\n",
    "1. Create a class (without peeking, if possible!) and use it.\n",
    "1. What does `x[:,0]` return?\n",
    "1. Rewrite the `DotProduct` class (without peeking, if possible!) and train a model with it.\n",
    "1. What is a good loss function to use for MovieLens? Why? \n",
    "1. What would happen if we used cross-entropy loss with MovieLens? How would we need to change the model?\n",
    "1. What is the use of bias in a dot product model?\n",
    "1. What is another name for weight decay?\n",
    "1. Write the equation for weight decay (without peeking!).\n",
    "1. Write the equation for the gradient of weight decay. Why does it help reduce weights?\n",
    "1. Why does reducing weights lead to better generalization?\n",
    "1. What does `argsort` do in PyTorch?\n",
    "1. Does sorting the movie biases give the same result as averaging overall movie ratings by movie? Why/why not?\n",
    "1. How do you print the names and details of the layers in a model?\n",
    "1. What is the \"bootstrapping problem\" in collaborative filtering?\n",
    "1. How could you deal with the bootstrapping problem for new users? For new movies?\n",
    "1. How can feedback loops impact collaborative filtering systems?\n",
    "1. When using a neural network in collaborative filtering, why can we have different numbers of factors for movies and users?\n",
    "1. Why is there an `nn.Sequential` in the `CollabNN` model?\n",
    "1. What kind of model should we use if we want to add metadata about users and items, or information such as date and time, to a collaborative filtering model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Research\n",
    "\n",
    "1. Take a look at all the differences between the `Embedding` version of `DotProductBias` and the `create_params` version, and try to understand why each of those changes is required. If you're not sure, try reverting each change to see what happens. (NB: even the type of brackets used in `forward` has changed!)\n",
    "1. Find three other areas where collaborative filtering is being used, and find out what the pros and cons of this approach are in those areas.\n",
    "1. Complete this notebook using the full MovieLens dataset, and compare your results to online benchmarks. See if you can improve your accuracy. Look on the book's website and the fast.ai forum for ideas. Note that there are more columns in the full dataset—see if you can use those too (the next chapter might give you ideas).\n",
    "1. Create a model for MovieLens that works with cross-entropy loss, and compare it to the model in this chapter."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
